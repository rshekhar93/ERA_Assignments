{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build CNN on MNIST data with following features:\n",
    "- data augmentation\n",
    "- advance CNN architecture\n",
    "- optimized on least model parameters with maximum accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import warnings\n",
    "\n",
    "# Ignore specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Summary:\n",
    "1. **Target:** \n",
    "    - First Model, Have the right setup\n",
    "    - Make the code modular\n",
    "    - Include data loader and training & test loop\n",
    "2. **Results:** \n",
    "    - Parameters: 6.3M\n",
    "    - Best Training Accuracy: 99.99\n",
    "    - Best Test Accuracy: 99.24\n",
    "3. **Analysis:** \n",
    "    - sdfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_epochs': 15, 'batch_size': 64, 'learning_rate': 0.0009, 'dropout_rate': 0.25, 'num_classes': 10, 'momentum': 0.9, 'random_seed': 193}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters class for easy tuning\n",
    "class HyperParameters:\n",
    "    def __init__(self):\n",
    "        self.num_epochs = 15\n",
    "        self.batch_size = 64\n",
    "        self.learning_rate = 0.0009\n",
    "        self.dropout_rate = 0.25\n",
    "        self.num_classes = 10\n",
    "        self.momentum = 0.9\n",
    "        self.random_seed = 193\n",
    "\n",
    "# Initialize hyperparameters\n",
    "params = HyperParameters()\n",
    "print(params.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformations & Tain/Test data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Phase transformations\n",
    "train_transforms = transforms.Compose([\n",
    "                                      #  transforms.Resize((28, 28)),\n",
    "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
    "                                    #    transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.1307,), (0.3081,)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values.\n",
    "                                       # Note the difference between (0.1307) and (0.1307,)\n",
    "                                       ])\n",
    "\n",
    "# Test Phase transformations\n",
    "test_transforms = transforms.Compose([\n",
    "                                      #  transforms.Resize((28, 28)),\n",
    "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                       ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "train = datasets.MNIST('./../data', train=True, download=True, transform=train_transforms)\n",
    "test = datasets.MNIST('./../data', train=False, download=True, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available? True\n"
     ]
    }
   ],
   "source": [
    "# Create data loaders\n",
    "\n",
    "# CUDA?\n",
    "cuda = torch.cuda.is_available()\n",
    "print(\"CUDA Available?\", cuda)\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(params.random_seed)\n",
    "\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(params.random_seed)\n",
    "\n",
    "# dataloader arguments - something you'll fetch these from cmdprmt\n",
    "dataloader_args = dict(shuffle=True, batch_size=params.batch_size, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=params.batch_size)\n",
    "\n",
    "# train dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
    "\n",
    "# test dataloader\n",
    "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_value = params.dropout_rate\n",
    "class TinyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TinyCNN, self).__init__()\n",
    "        # Input Block\n",
    "        self.convblock1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=4, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(4),\n",
    "            # nn.Dropout(dropout_value)\n",
    "        ) # output_size = 26\n",
    "\n",
    "        # CONVOLUTION BLOCK 1\n",
    "        self.convblock2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=8, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(8),\n",
    "            # nn.Dropout(dropout_value)\n",
    "        ) # output_size = 24\n",
    "\n",
    "        # TRANSITION BLOCK 1\n",
    "        self.convblock3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(1, 1), padding=0, bias=False),\n",
    "        ) # output_size = 24\n",
    "        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 12\n",
    "\n",
    "        # CONVOLUTION BLOCK 2\n",
    "        self.convblock4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            # nn.Dropout(dropout_value)\n",
    "        ) # output_size = 10\n",
    "        self.convblock5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(16),\n",
    "            # nn.Dropout(dropout_value)\n",
    "        ) # output_size = 8\n",
    "        self.convblock6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=8, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(8),\n",
    "            # nn.Dropout(dropout_value)\n",
    "        ) # output_size = 6\n",
    "        self.convblock7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(16),\n",
    "            # nn.Dropout(dropout_value)\n",
    "        ) # output_size = 6\n",
    "\n",
    "        # OUTPUT BLOCK\n",
    "        self.gap = nn.Sequential(\n",
    "            nn.AvgPool2d(kernel_size=6)\n",
    "        ) # output_size = 1\n",
    "\n",
    "        self.convblock8 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
    "            # nn.BatchNorm2d(10),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(dropout_value)\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_value)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convblock1(x)\n",
    "        x = self.convblock2(x)\n",
    "        x = self.convblock3(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.convblock4(x)\n",
    "        x = self.convblock5(x)\n",
    "        x = self.convblock6(x)\n",
    "        x = self.convblock7(x)\n",
    "        x = self.gap(x)\n",
    "        x = self.convblock8(x)\n",
    "\n",
    "        x = x.view(-1, 10)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 4, 26, 26]              36\n",
      "              ReLU-2            [-1, 4, 26, 26]               0\n",
      "       BatchNorm2d-3            [-1, 4, 26, 26]               8\n",
      "           Dropout-4            [-1, 4, 26, 26]               0\n",
      "            Conv2d-5            [-1, 8, 24, 24]             288\n",
      "              ReLU-6            [-1, 8, 24, 24]               0\n",
      "       BatchNorm2d-7            [-1, 8, 24, 24]              16\n",
      "           Dropout-8            [-1, 8, 24, 24]               0\n",
      "            Conv2d-9           [-1, 16, 24, 24]             128\n",
      "        MaxPool2d-10           [-1, 16, 12, 12]               0\n",
      "           Conv2d-11           [-1, 32, 10, 10]           4,608\n",
      "             ReLU-12           [-1, 32, 10, 10]               0\n",
      "      BatchNorm2d-13           [-1, 32, 10, 10]              64\n",
      "          Dropout-14           [-1, 32, 10, 10]               0\n",
      "           Conv2d-15             [-1, 16, 8, 8]           4,608\n",
      "             ReLU-16             [-1, 16, 8, 8]               0\n",
      "      BatchNorm2d-17             [-1, 16, 8, 8]              32\n",
      "          Dropout-18             [-1, 16, 8, 8]               0\n",
      "           Conv2d-19              [-1, 8, 6, 6]           1,152\n",
      "             ReLU-20              [-1, 8, 6, 6]               0\n",
      "      BatchNorm2d-21              [-1, 8, 6, 6]              16\n",
      "          Dropout-22              [-1, 8, 6, 6]               0\n",
      "           Conv2d-23             [-1, 16, 6, 6]           1,152\n",
      "             ReLU-24             [-1, 16, 6, 6]               0\n",
      "      BatchNorm2d-25             [-1, 16, 6, 6]              32\n",
      "          Dropout-26             [-1, 16, 6, 6]               0\n",
      "        AvgPool2d-27             [-1, 16, 1, 1]               0\n",
      "           Conv2d-28             [-1, 10, 1, 1]             160\n",
      "================================================================\n",
      "Total params: 12,300\n",
      "Trainable params: 12,300\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.47\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.52\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "model = TinyCNN().to(device)\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "def train(model, device, train_loader, optimizer):\n",
    "  model.train()\n",
    "  pbar = tqdm(train_loader)\n",
    "  correct = 0\n",
    "  processed = 0\n",
    "  for batch_idx, (data, target) in enumerate(pbar):\n",
    "    # get samples\n",
    "    data, target = data.to(device), target.to(device)\n",
    "\n",
    "    # Init\n",
    "    optimizer.zero_grad()\n",
    "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes.\n",
    "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model(data)\n",
    "\n",
    "    # Calculate loss\n",
    "    loss = F.nll_loss(y_pred, target)\n",
    "    train_losses.append(loss)\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Update pbar-tqdm\n",
    "\n",
    "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    processed += len(data)\n",
    "\n",
    "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
    "    train_acc.append(100*correct/processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "    test_acc.append(100. * correct / len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.32955360412597656 Batch_id=937 Accuracy=87.03: 100%|██████████| 938/938 [00:12<00:00, 75.82it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1269, Accuracy: 9609/10000 (96.09%)\n",
      "\n",
      "EPOCH: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.2422572523355484 Batch_id=937 Accuracy=96.28: 100%|██████████| 938/938 [00:12<00:00, 76.23it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0782, Accuracy: 9774/10000 (97.74%)\n",
      "\n",
      "EPOCH: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.1542239487171173 Batch_id=937 Accuracy=96.87: 100%|██████████| 938/938 [00:12<00:00, 77.43it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0542, Accuracy: 9823/10000 (98.23%)\n",
      "\n",
      "EPOCH: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.17775803804397583 Batch_id=937 Accuracy=97.31: 100%|██████████| 938/938 [00:12<00:00, 72.92it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0578, Accuracy: 9809/10000 (98.09%)\n",
      "\n",
      "EPOCH: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.4633793830871582 Batch_id=937 Accuracy=97.49: 100%|██████████| 938/938 [00:15<00:00, 62.44it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0529, Accuracy: 9823/10000 (98.23%)\n",
      "\n",
      "EPOCH: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.011801096610724926 Batch_id=937 Accuracy=97.64: 100%|██████████| 938/938 [00:15<00:00, 60.48it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0406, Accuracy: 9870/10000 (98.70%)\n",
      "\n",
      "EPOCH: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.022551337257027626 Batch_id=937 Accuracy=97.75: 100%|██████████| 938/938 [00:17<00:00, 53.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0462, Accuracy: 9866/10000 (98.66%)\n",
      "\n",
      "EPOCH: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.06254660338163376 Batch_id=937 Accuracy=97.86: 100%|██████████| 938/938 [00:17<00:00, 54.53it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0551, Accuracy: 9837/10000 (98.37%)\n",
      "\n",
      "EPOCH: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.11378300935029984 Batch_id=937 Accuracy=97.91: 100%|██████████| 938/938 [00:17<00:00, 54.33it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0386, Accuracy: 9891/10000 (98.91%)\n",
      "\n",
      "EPOCH: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.05129801854491234 Batch_id=937 Accuracy=98.05: 100%|██████████| 938/938 [00:15<00:00, 60.67it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0425, Accuracy: 9876/10000 (98.76%)\n",
      "\n",
      "EPOCH: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.0416073314845562 Batch_id=937 Accuracy=98.03: 100%|██████████| 938/938 [00:17<00:00, 54.51it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0458, Accuracy: 9863/10000 (98.63%)\n",
      "\n",
      "EPOCH: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.23300392925739288 Batch_id=937 Accuracy=98.07: 100%|██████████| 938/938 [00:16<00:00, 56.77it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0423, Accuracy: 9868/10000 (98.68%)\n",
      "\n",
      "EPOCH: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.08978545665740967 Batch_id=937 Accuracy=98.19: 100%|██████████| 938/938 [00:16<00:00, 57.46it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0459, Accuracy: 9855/10000 (98.55%)\n",
      "\n",
      "EPOCH: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.011662577278912067 Batch_id=937 Accuracy=98.22: 100%|██████████| 938/938 [00:17<00:00, 55.14it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0446, Accuracy: 9864/10000 (98.64%)\n",
      "\n",
      "EPOCH: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.013190542347729206 Batch_id=937 Accuracy=98.17: 100%|██████████| 938/938 [00:17<00:00, 53.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0529, Accuracy: 9850/10000 (98.50%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "model =  TinyCNN().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "# scheduler = StepLR(optimizer, step_size=6, gamma=0.1)\n",
    "\n",
    "\n",
    "EPOCHS = params.num_epochs\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"EPOCH:\", epoch)\n",
    "    train(model, device, train_loader, optimizer)\n",
    "    # scheduler.step()\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "era_gpu",
   "language": "python",
   "name": "era_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
